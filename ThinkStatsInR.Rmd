---
title: "thinkstats"
output: html_document
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(tidyverse)
library(plotly)
```

The data source is obtained from https://www.cdc.gov/nchs/nsfg/nsfg_cycle6.htm
This contains fixed width files, and stata dictionaries consisting of columns for the data files
```{r}
#helper function to parse Stata dictionary
dct.parser <- function(dct, includes = c("StartPos", "StorageType", "ColName", 
                                         "ColWidth", "VarLabel"),
                       preview = FALSE) {
  temp <- readLines(dct)
  temp <- temp[grepl("_column", temp)]
  
  if (isTRUE(preview)) {
    head(temp)
  } else {
    possibilities <- c("StartPos", "StorageType", 
                       "ColName", "ColWidth", "VarLabel")
    classes <- c("numeric", "character", "
                 character", "numeric", "character")
    pattern <- c(StartPos = ".*\\(([0-9 ]+)\\)",
                 StorageType = "(byte|int|long|float|double|str[0-9]+)",
                 ColName = "(.*)",
                 ColWidth = "%([0-9.]+)[a-z]+",
                 VarLabel = "(.*)")
    
    mymatch <- match(includes, possibilities)
    
    pattern <- paste(paste(pattern[mymatch], 
                           collapse ="\\s+"), "$", sep = "")    
    
    metadata <- setNames(lapply(seq_along(mymatch), function(x) {
      out <- gsub(pattern, paste("\\", x, sep = ""), temp)
      out <- gsub("^\\s+|\\s+$", "", out)
      out <- gsub('\"', "", out, fixed = TRUE)
      class(out) <- classes[mymatch][x] ; out }), 
                         possibilities[mymatch])
    
    implicit.dec <- grepl("\\.[1-9]", metadata[["ColWidth"]])
    if (any(implicit.dec)) {
      message("Some variables may need to be corrected for implicit decimals. 
              Try 'MESSAGES(output_from_dct.parser)' for more details.")
      metadata[["Decimals"]] <- rep(NA, length(metadata[["ColWidth"]]))
      metadata[["Decimals"]][implicit.dec] <-
        as.numeric(gsub("[0-9]+\\.", "", 
                        metadata[["ColWidth"]][implicit.dec]))
      metadata[["ColWidth"]] <- floor(as.numeric(metadata[["ColWidth"]]))
    }
    
    metadata[["ColName"]] <- make.names(
      gsub("\\s", "", metadata[["ColName"]]))
    
    metadata <- data.frame(metadata)
    
    if ("StorageType" %in% includes) {
      metadata <- 
        within(metadata, {
          colClasses <- ifelse(
            StorageType == "byte", "raw",
            ifelse(StorageType %in% c("double", "long", "float"), 
                   "numeric", 
                   ifelse(StorageType == "int", "integer",
                          ifelse(substr(StorageType, 1, 3) == "str", 
                                 "character", NA))))
        })
    }
    if (any(implicit.dec)) {
      attr(metadata, "MESSAGE") <- c(sprintf("%s", paste(
        "Some variables might need to be corrected for implicit decimals. 
        A variable, 'Decimals', has been created in the metadata that
        indicates the number of decimal places the variable should hold. 
        To correct the output, try (where your stored output is 'mydf'): 
        
        lapply(seq_along(mydf[!is.na(Decimals)]), 
        function(x) mydf[!is.na(Decimals)][x]
        / 10^Decimals[!is.na(Decimals)][x])
        
        The variables in question are:
        ")), sprintf("%s", metadata[["ColName"]][!is.na(metadata[["Decimals"]])]))
            class(attr(metadata, "MESSAGE")) <- c(
                "MESSAGE", class(attr(metadata, "MESSAGE")))
        }
        attr(metadata, "original.dictionary") <- 
            c(dct, basename(dct))
        metadata
    }
}
```


We can read the coulmns from 2002FemPreg.dct and use those columns to import the data from the fixed width file 2002FemPreg.dat
```{r}
femPreg2002columns <- dct.parser('~/Documents/CodeWork/ThinkStats2/code/2002FemPreg.dct')
femPreg2002 <- read.fwf('~/Documents/CodeWork/ThinkStats2/code/2002FemPreg.dat', widths = femPreg2002columns$ColWidth, col.names = femPreg2002columns$ColName)
```

Taking a look at the data
```{r}
head(femPreg2002)
```

We can see a lot of missing values. We'll clean the data for the columns that we want to analyze.

## Transformation

1. agepreg contains the mother's age at the end of the pregnancy. In the data file, agepreg is encoded as an integer number of centiyears. So the first line divides each element of agepreg by 100, yielding a floating-point value in years.

2. birthwgt_lb and birthwgt_oz contain the weight of the baby, in pounds and ounces, for pregnancies that end in live birth. In addition it uses several special codes:
  97 NOT ASCERTAINED
  98 REFUSED
  99 DONT KNOW
Special values encoded as numbers are dangerous because if they are not
handled properly, they can generate bogus results, like a 99-pound baby. Assuming that a baby can't be generally more than 20 lb at birth, we will replace all other values with NA, as they are NOT ASCERTAINED(97),  REFUSED(98), DONT KNOW(99), or invalid values.
Similarly, the age of father has these similar special codes, which we will replace by NA
```{r}
cleanFemPreg <- function(data){
  # mother's age is encoded in centiyears; convert to years
  data['agepreg'] <-  data['agepreg']/100.0
  
  # birthwgt_lb contains at least one bogus value (51 lbs)
  # replace with NaN
  data$birthwgt_lb[data$birthwgt_lb > 20] <- NA
  
  # replace 'not ascertained', 'refused', 'don't know' with NA
  na_vals = c(97, 98, 99)
  data$birthwgt_oz[data$birthwgt_oz %in% na_vals] <- NA
  data$hpagelb[data$hpagelb %in% na_vals] <- NA
  
  # birthweight is stored in two columns, lbs and oz.
  # convert to a single column in lb
  data['totalwgt_lb'] <- data$birthwgt_lb + (data$birthwgt_oz / 16.0)
  
  return (data)
}
```

```{r}
femPregCleaned <- cleanFemPreg(femPreg2002)
```

### Validation
One way to validate data is to compute basic statistics and compare them with published results. For example, the NSFG codebook includes tables that summarize each variable. Here is the table for outcome, which encodes the outcome of each pregnancy:
value     label         Total
1         LIVE BIRTH        9148
2         INDUCED ABORTION  1862
3         STILLBIRTH        120
4         MISCARRIAGE       1921
5         ECTOPIC PREGNANCY 190
6         CURRENT PREGNANCY 352

```{r}
femPreg2002 %>%
  group_by(outcome) %>%
  summarise(Total = length(outcome))
```

Comparing the results with the published table, it looks like the values in
outcome are correct. Similarly, here is the published table for birthwgt_lb
value     label             Total
.         INAPPLICABLE      4449
0-5       UNDER 6 POUNDS    1125
6         6 POUNDS          2223
7         7 POUNDS          3049
8         8 POUNDS          1889
9-95      9 POUNDS OR MORE  799

```{r}
femPreg2002 %>%
  group_by(birthwgt_lb) %>%
  summarise(Total = length(birthwgt_lb))
```

The counts for 6, 7, and 8 pounds check out, and if you add up the counts
for 0-5 and 9-95, they check out, too. But if you look more closely, you will
notice one value that has to be an error, a 51 pound baby! This has been cleaned in the cleanFemPreg function.

### Interpretation
To work with data effectively, you have to think on two levels at the same time: the level of statistics and the level of context.
As an example, let's look at the sequence of outcomes for a few respondents.
This example looks up one respondent and prints a list of outcomes for her
pregnancies:
```{r}
CASEID = 10229
femPregCleaned %>%
  filter(caseid==CASEID) %>%
  .$outcome
```
The outcome code 1 indicates a live birth. Code 4 indicates a miscarriage; that is, a pregnancy that ended spontaneously, usually with no known medical cause.

Statistically this respondent is not unusual. Miscarriages are common and there are other respondents who reported as many or more. But remembering the context, this data tells the story of a woman who was pregnant six times, each time ending in miscarriage. Her seventh and most recent pregnancy ended in a live birth. If we consider this data with empathy,
it is natural to be moved by the story it tells.

Each record in the NSFG dataset represents a person who provided honest answers to many personal and difficult questions. We can use this data to answer statistical questions about family life, reproduction, and health. At the same time, we have an obligation to consider the people represented by the data, and to afford them respect and gratitude.

## Distributions
```{r}
#helper theme for common visualizations
ditch_the_axes <- theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
  )
```
### Histograms
One of the best ways to describe a variable is to report the values that appear in the dataset and how many times each value appears. This description is called the distribution of the variable.
The most common representation of a distribution is a histogram, which is a graph that shows the frequency of each value. In this context, "frequency" means the number of times the value appears.

When you start working with a new dataset, we suggest you explore the variables you are planning to use one at a time, and a good way to start is by looking at histograms.

We transformed agepreg from centiyears to years, and combined birthwgt_lb and birthwgt_oz into a single quantity, totalwgt_lb. In this section we use these variables to demonstrate some features of histograms.

We start by reading the data and selecting records for live births:
```{r}
live <- femPregCleaned %>%
  filter(outcome==1)
```
Next we generate and plot the histogram of birthwgt_lb for live births.
```{r}
live %>%
  ggplot(mapping = aes(birthwgt_lb)) + 
  geom_histogram(bins = 16, color = 'black', fill='light blue', na.rm = TRUE) +
  labs(x = "pounds", y="Frequency")
```
The most common value, called the mode, is 7 pounds. The distribution is approximately bell-shaped, which is the shape of the normal distribution, also called a Gaussian distribution. But unlike a true normal distribution, this distribution is asymmetric; it has a tail that extends farther to the left than to the right.

Let's look at the histogram for birthwgt_oz:
```{r}
live %>%
  ggplot(mapping = aes(birthwgt_oz)) + 
  geom_histogram(bins = 16, color = 'black', fill='light blue', na.rm = TRUE) +
  labs(x = "ounces", y="Frequency")
```
In theory we expect this distribution to be uniform; that is, all values should have the same frequency. In fact, 0 is more common than the other values, and 1 and 15 are less common, probably because respondents round off birth weights that are close to an integer value.

Let's look at the histogram for agepreg:
```{r}
live %>%
  ggplot(mapping = aes(agepreg)) + 
  geom_histogram(bins = 45, color = 'black', fill='light blue', na.rm = TRUE) +
  labs(x = "years", y="Frequency")
```
The mode is 21 years. The distribution is very roughly bell-shaped, but in this case the tail extends farther to the right than left; most mothers are in their 20s, fewer in their 30s.

Let's look at the prglength:
```{r}
live %>%
  ggplot(mapping = aes(prglngth)) + 
  geom_histogram(bins = 50, color = 'black', fill='light blue', na.rm = TRUE) +
  labs(x = "weeks", y="Frequency")
```
By far the most common value is 39 weeks. The left tail is longer than the right; early babies are common, but pregnancies seldom go past 43 weeks, and doctors often intervene if they do.

### Outliers
Looking at histograms, it is easy to identify the most common values and the shape of the distribution, but rare values are not always visible. Before going on, it is a good idea to check for outliers, which are extreme values that might be errors in measurement and recording, or might be accurate reports of rare events.

```{r}
live['prglngth'] %>%
  distinct %>% 
  top_n(-10) %>%
  arrange(prglngth)
```
In the list of pregnancy lengths for live births, the 10 lowest values are [0, 4, 9, 13, 17, 18, 19, 20, 21, 22]. Values below 10 weeks are certainly errors; the most likely explanation is that the outcome was not coded correctly. Values higher than 30 weeks are probably legitimate. Between 10 and 30 weeks, it is hard to be sure; some values are probably errors, but some represent premature babies.

On the other end of the range, the highest values are:
```{r}
live['prglngth'] %>%
  distinct %>% 
  top_n(7) %>%
  arrange(prglngth)
```
Most doctors recommend induced labor if a pregnancy exceeds 42 weeks, so some of the longer values are surprising. In particular, 50 weeks seems medically unlikely.

The best way to handle outliers depends on "domain knowledge"; that is, information about where the data come from and what they mean. And it depends on what analysis you are planning to perform.
In this example, the motivating question is whether first babies tend to be early (or late). When people ask this question, they are usually interested in full-term pregnancies, so for this analysis we will focus on pregnancies longer than 27 weeks.
### First babies
Now we can compare the distribution of pregnancy lengths for first babies and others. We divide the data of live births using birthord to create a new column birthNumber, and compute their histograms:
```{r}
live['birthNumber'] <- if_else(live$birthord==1, 'first', 'other')
```

```{r}
live %>%
  ggplot(aes(x=prglngth, fill=birthNumber)) + 
  geom_histogram(bins=20, position="dodge", na.rm = TRUE) +
  labs(x="Weeks", y="Frequency") + 
  theme(legend.position = c(0.2, 0.7)) + 
  xlim(27, 46)
```
Histograms are useful because they make the most frequent values immediately apparent. But they are not the best choice for comparing two distributions. In this example, there are fewer "first babies" than "others," so some of the apparent differences in the histograms are due to sample sizes. In the next chapter we address this problem using probability mass functions.

### Effect Size
An effect size is a summary statistic intended to describe the size of an effect. For example, to describe the difference between two groups, one obvious choice is the difference in the means.
Mean pregnancy length for first babies is 38.601; for other babies it is 38.523. The difference is 0.078 weeks, which works out to 13 hours. As a fraction of the typical pregnancy length, this difference is about 0.2%. 
If we assume this estimate is accurate, such a difference would have no practical consequences. In fact, without observing a large number of pregnancies, it is unlikely that anyone would notice this difference at all.
Another way to convey the size of the effect is to compare the difference between groups to the variability within groups. Cohen's d is a statistic intended to do that; it is defined
d = (_x1_ - _x2_)/s
where _x1_ and _x2_ are the means of the groups and s is the "pooled standard
deviation".
```{r}
CohenEffectSize <- function(group1, group2){
  diff = mean(group1, na.rm = TRUE) - mean(group2, na.rm = TRUE)
  
  var1 = var(group1, na.rm=TRUE)
  var2 = var(group2, na.rm=TRUE)
  n1 = length(group1)
  n2 = length(group2)
  
  pooled_var = (n1*var1 + n2*var2)/(n1+n2)
  d = diff/sqrt(pooled_var)
  return (d)
}
```

Let's look at the effect size for difference in totalwgt_lb for first babies vs other babies. 
```{r}
firstBirthWgt <- live %>%
  filter(birthord==1) %>%
  .$totalwgt_lb

othersBirthWgt <- live %>%
  filter(birthord!=1) %>%
  .$totalwgt_lb
CohenEffectSize(firstBirthWgt, othersBirthWgt)
```

## Probability Mass Functions
By plotting the PMF instead of the histogram, we can compare the two distributions without being mislead by the difference in sample size.
```{r}
live %>%
  ggplot(aes(x=prglngth, ..density.., fill=birthNumber)) + 
  geom_histogram(bins = 20, stat="bin", position = "dodge", na.rm = TRUE) +
  labs(x="weeks", y="probability") + 
  theme(legend.position = c(0.2, 0.7)) + 
  xlim(27, 46)
```
```{r}
live %>%
  ggplot(aes(x=prglngth, ..density.., color=birthNumber)) +
  geom_step(binwidth = 0.7, stat="bin", position = "identity", na.rm = TRUE) +
  labs(x="weeks", y="probability") + 
  theme(legend.position = c(0.2, 0.7)) + 
  xlim(27, 46)
```

Based on this figure, first babies seem to be less likely than others to arrive on time (week 39) and more likely to be a late (weeks 41 and 42).

### Other visualizations
Histograms and PMFs are useful while you are exploring data and trying to identify patterns and relationships. Once you have an idea what is going on, a good next step is to design a visualization that makes the patterns you have identified as clear as possible.

In the NSFG data, the biggest differences in the distributions are near the mode. So it makes sense to zoom in on that part of the graph, and to transform the data to emphasize differences:

```{r}
#get the proportion of different number of weeks for prglngth, by order of birth
prglngthProp <- (table(live$prglngth, live$birthNumber) %>%
  prop.table(2) * 100 )%>%
  data.frame()
prglngthProp['weeks'] <- prglngthProp[, 'Var1'] %>%
  as.character %>%
  as.integer
```

```{r}
#filter for zooming from 35 to 46 weeks
p1 <- prglngthProp %>%
  subset(weeks>=35 & weeks<= 46 & Var2=='first') %>%
  .[c('weeks', 'Freq')]
  
p2 <- prglngthProp %>%
  subset(weeks>=35 & weeks<= 46 & Var2=='other') %>%
  .[c('weeks', 'Freq')]
```

```{r}
#find difference between the frequencies
diff <- within(merge(p1, p2, by='weeks'), {
  weeks <- weeks
  percent_points <- Freq.x - Freq.y
})[c('weeks', 'percent_points')]
```


```{r}
diff %>%
  ggplot(aes(x=weeks)) +
  geom_bar() +
  labs(x="weeks", y="percentage points") #+ 
  #theme(legend.position = c(0.2, 0.7)) + 
  #xlim(27, 46)
```
